{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 测试一下工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyd/anaconda3/envs/vault/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117 0.15.1+cpu\n",
      "cuda is available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchtext\n",
    "print(torch.__version__, torchtext.__version__)\n",
    "print(\"cuda is available: \", torch.cuda.is_available())\n",
    "from torchdata.datapipes.iter import IterableWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 初始数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build data processing pipeline to convert the raw text strings into Tensor that can be used to train the model\n",
    "2. Shuffle and iterate the data with DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "\n",
    "train_iter = iter(AG_NEWS(split=\"train\"))\n",
    "# iter创建了一个迭代器对象，每次调用这个迭代器对象的__next__()方法时，\n",
    "# 都会调用object, split表示使用的划分是训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用时遇到了无法连接到githubusercontent的问题，解决方案为[csdn blog](https://blog.csdn.net/qq_32618327/article/details/106681211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 为处理数据做准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始的文本处理方法：包括vocab，词向量，tokenizer\n",
    "1. tokenizer:首先，将输入的文本按照一定规则切分成一系列的token；然后，在字典中查表，将每个token用一个整数编号来表示；最后，将字典中不存在的字（词）用特殊标识符（‘UNK’）表示，并赋予相应编号。\n",
    "2. yield:是Python 的一个关键字，用于从一个函数中返回一个生成器（generator）。生成器是一种特殊类型的迭代器，它允许你延迟计算结果，这在处理大数据或者创建复杂数据结构时特别有用，因为你不需要一次性将所有的数据都存储在内存中。一个使用 yield 的函数会被称为生成器函数。这种函数并不直接返回一个值，而是生成一系列的值。每次调用这个生成器函数，它会从上次离开的地方继续执行，并且可以产生许多结果，而不是单个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function: build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train_iter = AG_NEWS(split=\"train\")\n",
    "\n",
    "\n",
    "# define a yield list of tokens\n",
    "def yield_tokens(data_iter):\n",
    "    for _,text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "# specials（List[str]，optional）：指定一些特殊的词，比如UNK、PAD、BOS和EOS等\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter),specials=[\"<unk>\"])\n",
    "\n",
    "# Value of default index. This index will be returned when OOV token is queried.\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab converts a list of tokens into integers\n",
    "# 在这个文本数据集上，没有@等这些奇怪的字符，所以变为了0\n",
    "vocab(['here', 'is', 'an', 'example','@', \"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入的x为一个句子，将其转化为数字列表\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMPHIS, Tenn. – Four days ago, Jon Rahm was     enduring the season’s worst weather conditions on Sunday at The     Open on his way to a closing 75 at Royal Portrush, which     considering the wind and the rain was a respectable showing.     Thursday’s first round at the WGC-FedEx St. Jude Invitational     was another story. With temperatures in the mid-80s and hardly any     wind, the Spaniard was 13 strokes better in a flawless round.     Thanks to his best putting performance on the PGA Tour, Rahm     finished with an 8-under 62 for a three-stroke lead, which     was even more impressive considering he’d never played the     front nine at TPC Southwind.\n",
      "memphis tenn four days ago jon rahm was live the seasons worst weather term on sunday at the open on his way to a closing at purple portrush which considering the wind and the rainfall was a respectable showing thursdays first round at the wgc fedex st st jude invitational was another narrative with temperatures in the mid s and hardly any wind the spaniard was strokes better in a flawless round thanks to his best set up public presentation on the pga tour rahm finished with an under for a three cam stroke steer which was even more impressive considering hed never played the front nine at tpc southwind\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 3096,     3,  6691,     1,     0,   161,   301,   349,     3,  4774,\n",
       "             0,    35, 12839,     2,     0,  1598,  1424,  2056,    10,    91,\n",
       "            20,     2,   149,    10,    32,   249,     4,     5,  1914,  2642,\n",
       "            20,  1703, 83143,     3,   103,  1879,     2,  3030,     8,     2,\n",
       "          1594,    35,     5, 19246,  1646,     1,     0,    47,   426,    20,\n",
       "             2,     0,   425,     1, 24223,  5965,    35,   206,  1855,     1,\n",
       "            18,  6640,     7,     2,     0,     8,  5666,   457,  3030,     3,\n",
       "             2,  6434,    35,   732,  4994,   637,     7,     5, 14920,   426,\n",
       "             1,  1806,     4,    32,   502,  2072,   847,    10,     2,  2076,\n",
       "           712,     3,     0,  2034,    18,    30, 15250,  4062,    11,     5,\n",
       "         12098,   170,     3,   103,    35,   331,    46,  3934,  1879,     0,\n",
       "           972,  1258,     2,  1450,   799,    20, 15192,     0,     1]),\n",
       " tensor([ 3096,  6691,   161,   301,   349,  4774,     0,    35,  1628,     2,\n",
       "          2651,  1598,  1424,  1314,    10,    91,    20,     2,   149,    10,\n",
       "            32,   249,     4,     5,  1914,    20, 18301, 83143,   103,  1879,\n",
       "             2,  3030,     8,     2, 15097,    35,     5, 19246,  1646, 40102,\n",
       "            47,   426,    20,     2, 15756,  4480,   425,   425, 24223,  5965,\n",
       "            35,   206, 24415,    18,  6640,     7,     2, 15029,     9,     8,\n",
       "          5666,   457,  3030,     2,  6434,    35,  4994,   637,     7,     5,\n",
       "         14920,   426,  1806,     4,    32,   502,   166,    43,   384,  9247,\n",
       "            10,     2,  2076,   712,     0,  2034,    18,    30,   267,    11,\n",
       "             5,    94, 63341,  4077,  9719,   103,    35,   331,    46,  3934,\n",
       "          1879, 32236,   972,  1258,     2,  1450,   799,    20, 15192,     0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code in eda.py\n",
    "from eda import eda, get_only_chars\n",
    "\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "\n",
    "a = text_pipeline(ex_text_str)\n",
    "b_str = eda(ex_text_str)[2]\n",
    "b = text_pipeline(b_str)\n",
    "print(ex_text_str)\n",
    "print(b_str)\n",
    "torch.tensor(a), torch.tensor(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 生成数据集迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用DataLoader，需要实现getitem和len方法,需要自行定义collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        # 插入的是每个句子的长度\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    # 这里的text_list是one-dim的输入，因为每一个句子的长度不同，并且没有填充使得每个句子的长度相同\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split=\"train\")\n",
    "dataloader = DataLoader(train_iter, batch_size=16, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 定义分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用EmbeddingBag layer和线性层作为分类器。\n",
    "1. EmbeddingBag layer为bag中embeddings的均值,和，max，详细的用法[Doc](https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag).\n",
    "2. ``nn.EmbeddingBag`` module requires no padding here since the text lengths are saved in offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextCLSModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.initrange = 0.5\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # 对嵌入层初始化\n",
    "        self.embedding.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        # 将线性layer bias初始化为0\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets=None):\n",
    "        # 一维的text idx向量，一定需要offset参数\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表长度为:  95811\n"
     ]
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab) # 词汇表的长度\n",
    "print(\"词汇表长度为: \", vocab_size)\n",
    "emsize = 64\n",
    "model = TextCLSModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备训练\n",
    "torch.nn.utils.clip_grad_norm_：梯度剪裁，防止梯度爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader, optimizer, criterion, epoch:int):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        pred_label = model(text, offsets)\n",
    "        loss = criterion(pred_label, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度剪裁，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (pred_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1688 batches | accuracy    0.933\n",
      "| epoch   1 |  1000/ 1688 batches | accuracy    0.933\n",
      "| epoch   1 |  1500/ 1688 batches | accuracy    0.932\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  5.26s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1688 batches | accuracy    0.941\n",
      "| epoch   2 |  1000/ 1688 batches | accuracy    0.938\n",
      "| epoch   2 |  1500/ 1688 batches | accuracy    0.934\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  5.13s | valid accuracy    0.932 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1688 batches | accuracy    0.948\n",
      "| epoch   3 |  1000/ 1688 batches | accuracy    0.950\n",
      "| epoch   3 |  1500/ 1688 batches | accuracy    0.952\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  5.10s | valid accuracy    0.936 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 3  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "# Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "total_accu = None\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "# Convert iterable-style dataset to map-style dataset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.9)\n",
    "split_train_, split_valid_ = random_split(train_dataset, \n",
    "                                          [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    "    )\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, optimizer, criterion, epoch)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step() # 表示学习率太大了，需要降低学习率\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在测试集实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.907\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_dataloader)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在其他的随机news上测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sports news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1:\"world\", 2:\"sports\", 3:\"Business\", 4: \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0])) # offset为0表示只有一个文本\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s news\" % ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KDBC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
